### что сделано
В данном файле содержится код обучения модели Whisper(small). Модель Whisper была выбрана, так как изначально поддерживает
пунктуацию, поддерживает разные языки, достататочно просто обучается, показывает в целом хорошие результаты. Обучать старшие модели с помощью 
бесплатных ресурсов GPU на Kaggle или Colab не получилось. Однако, в случае хороших результатов файн-тьюнинга данной модели
можно будет арендовать мощности для экспериментов со старшими версиями.
Обучение проводилось на платформе Kaggle.

В качестве данных использовались:
1) Два датасета из ютуб видео, собранные самостоятельно. Об их содержании можно узнать из файла used_videos.csv,
 который находится в папке data/huggingface_youtube (100 и 50 часов аудио)
2) Часть датасета [Golos Crowd](https://github.com/sberdevices/golos) (суммарно 160 часов аудио)
3) Часть датасета [Sova (аудиокниги)](https://sova.ai/dataset/) (около 136 часов)

Код обучения, на данный момент, является достаточно классическим и мало отличается от распространенных гайдов, поэтому
подробное описание не делаю (на самом деле не очень успеваю)). В ходе дальнейшей работы планирую включить более сложные
преобразования, их опишу подробнее.

На данный момент экспериментировал только с включением тех или иных данных, с learning_rate и c schedule.
Результаты экспериментов, проведенных на данный момент можно посмотреть по 
[ссылке](https://docs.google.com/spreadsheets/d/1vsd9iQ2qUAH5_aU9c7Nzfe3kzIpl04B9UfRelyUrn1A/edit#gid=0).

### планы на (ближайшее) будущее
План-минимум: включить аугментации шумом. Попробовать их обрабатывать как с помощью обычного включения в обучающую
выборку зашумленных аудио, так и с помощью предварительной очистки от шумов отдельной программой и дальнейшим обучением
Whisper на спектрограммах очищенных аудио. 

План максимум: исследовать другие решения. В частности, использование языковых моделей. Кажется, что преимущество данного
подхода в том, что мы можем собрать гораздо больше необходимых данных в текстовом виде (спарсив хабр, тг-чатики и тд)




