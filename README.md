# MFDP

### Общая идея
Создание speech-to-text сервиса для транскрибирования корпоративных созвонов преимущественно в IT компаниях.  

### ML-часть
Дообучить открытое решение на данных близких к планируемой сфере применения. При обучении аугментировать аудио шумом, который специфичен сфере (щелчки мыши; разговор в офисе на заднем плане; шум из окна; домашние звуки, если сотрудник на удаленке; звук кафе, если сотрудник подключился оттуда)

#### Модели
На данный момент в качестве основной модели планируется использовать Whisper (small).

#### Данные
Помимо общедоступных датасетов Golos(crowd), Sova(audiobooks), и др, для обучения модели используются данные, собранные с платформы Youtube и обработанные самостоятельно. В качестве расшифровок используется автоматические сгенерированные субтитры платформы. Потребность в таких данных возникла в связи с тем, что:
1) не удалось найти открытые датасеты с длиной аудио более 10 секунд и состоящие более чем из 1 предложения на сэмпл.
2) самостоятельно можно собрать датасет из видео близких по содержанию к планируемой сфере использования (митапы, мок-интервью, подкасты про IT, и тд).

Небольшая часть данных собранный с платформы Youtube была размеченная вручную (на данный момент всего около часа материала). По сравнению с ней, качество автоматических субтитров не очень высокое. WER ошибка составляет около 0.15, не считая отсутствия знаков препинания. Однако по сравнению с ошибкой исходной Whisper small модели, которая составляет более 0.53, использование таких данных кажется оправданным, что подтверждают эксперименты. Также на данный момент не проводилась никакая предобработка автоматически сгенерированных субтитров. В частности в них встречаются такие вещи как 'java скрипт', которые, скорее всего, можно исправить с помощью нормализаторов текстов. Возможно такая обработка улучшит их качество.
