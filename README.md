# Recognize IT!
**- сервис для транскрибирования корпоративных звонков в IT компаниях**

*В данном репозитории представлены результаты работы над проектом в рамках курса My First Data Project.*

*Из предложенных тем, я выбрал четвертую, связанную с обработкой звука. Изначально в ней предлогалось сделать сервис, удаляющий шум из аудиозаписи. Однако, в ходе работы, мне захотелось измененить тему на разработку сервиса по распознаванию речи. Возможность такого изменения была согласована с организаторами курса.*

*Участник: Аносов Алексей Петрович*

## Структура репозитория
Репозиторий на данный момент состоит из двух папок:

1. service. в ней находится сам сервис
2. notebooks. в ней находятся все файлы и заметки отражающие ход работы.

Инструкция по запуску сервиса находится в папке service.


## Описание идеи
За последние три года видеозвонки прочно вошли в нашу жизнь. В будущем, как мне кажется, они будут составлять всё большую долю нашей профессиональной коммуникации. Видеозвонки имеют ряд преимуществ над обычными встречами, однако, можно постараться сделать их еще более удобными и эффективными. Среди возможных улучшений одним из самых очевидных является предоставление пользователям текстовых версий прошедших встреч. Такой функционал позволит:
1. сконцентрироваться во время звонка на обсуждении важных тем, не отвлекаясь на ведение заметок/конспектов
2. сотрудникам, которые не были на встрече, быстро узнать, что на ней обсуждалось
3. сотрудникам, которые опоздали, быстро ознакомиться с тем, что было до их прихода, не отвлекая коллег, и включиться в обсуждение (если транскрибирование происходит синхронно)
4. осуществлять поиск по содержанию прошедших встреч

Также имея хорошие текстовые расшировки можно предоставлять и другие сервисы. Например, суммаризацию встреч, или автоматизацию некоторых действий (например, автоматически создавать таски по результатам встречи).

В своем проекте, я попытался найти подходы к созданию сервиса распознавания речи для корпоративных звонков в IT компаниях.
Речь в данной сфере наполнена большим количеством специальной лексики: названия программ, фреймворков, моделей, и т.д. Это усложняет возможность создания расшифровок хорошего качества. Универсальные модели плохо справляются с этой задачей, так как 
1. в стандартных датасетах нет соответствующей лексики
2. часть терминов должна транскрибироваться с помощью латинских букв, но не все решения имеют возможность совмещать латиницу и кириллицу

С точки зрения бизнес-составляющей, создание такого сервиса кажется оправданным, так как часть популярных сервисов (Zoom, Google Meet) являются иностранными. Для иностранных сервисов работа с кириллицей всегда представляла сложности (Google проиграл Яндексу российский рынок). Тем более подобные сервисы не будут много заниматься кириллическими моделями в условиях нынешних санкций, когда российский рынок явно не является приоритетным. Таким образом пространство для сторонних сервисов будет открытым еще долгое время. 

Также стоит отметить, что идеи, реализованные в ходе данного проекта, могут быть в будущем использованы для дообучения моделей распознавания речи для других сфер, в которых присутствует большое количество специальной лексики.

## ML-часть

Пайплайн состоит из двух моделей:
1. Модель диаризации (разделения на спикеров)
2. Модель распознавания речи

Модель диаризации выдает временные метки разделения на спикеров. Согласно этим меткам исходное аудио нарезается на сегменты. В одном сегменте - одна реплика одного спикера. Далее эти сегменты передаются в модель распознавания. Результаты склеиваются и форматируются согласно заданным правилам, и выдаются пользователю.

### Модель диаризации
В качестве модели диаризации была выбрана open-source модель фреймворка Pyannote. Она признается сообществом одной из лучших. Модель на данном этапе не модифицировалась. Однако, ее улучшение может стать одним из направлений дальнейшей работы над сервисом.

### Модель распознавания речи
На данный момент за распознавание речи отвечает модель Whisper Small от OpenAI, так как: 
1. она легко обучается 
2. умеет включать в распознавание русского языка латинские символы
3. умеет хорошее качество

В ходе дообучения модели и усовершенствования инференсного пайплайна, было достугнуто улучшение на всех 10 используемых для валидации датасетах. На целевом датасете, основанном на Ютуб-видео с митапов и доразмеченном вручную полученны следующие результаты:

**здесь будет маленькая табличка с результатами**

wer -  расстояние Левенштейна на уровне слов, деленное на количество слов с правильном ответе (чем ниже, тем лучше)  
сer -  расстояние Левенштейна на уровне символов, деленное на количество слов в правильном ответе(чем ниже, тем лучше)  
keywords_rate - доля верно распознанных терминов (чем выше, тем лучше)

Подробное описание экспериментов содержится в ридми [директории notebooks](https://github.com/alexej-anosov/mfdp/tree/main/notebooks).

В будущем планируется провести эксперименты с другими моделями. В первую очередь [Vosk](https://alphacephei.com/vosk/models) и [NVIDIA Conformer-Transducer)](https://huggingface.co/nvidia/stt_ru_conformer_transducer_large)


## Сервис
На данный момент сервис представляет собой веб-страницу, на которой можно загрузить файл с компьютера или записать с помощью микрофона.
Распознанный текст выводится на экран. Его можно подкорректировать вручную и сохранить в виде txt-файла.

В будущем, планируется создание расширения для браузера, так как такая форма, кажется, наиболее естественной для такого приложения.

### Используемый стек
Backend: FastAPI  
Frontend: Bootstrap, JavaScript  
MLOps: Prometheus, Loki, Grafana, Locust

